{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next Word Genrator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaQacyWLlEJq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sli531vElGXy"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import os\n",
        "from argparse import Namespace"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNczaMTK2vVV"
      },
      "source": [
        "flags = Namespace(\n",
        "    train_file='oliver.txt',\n",
        "    seq_size=32,\n",
        "    batch_size=16,\n",
        "    embedding_size=64,\n",
        "    lstm_size=64,\n",
        "    gradients_norm=5,\n",
        "    initial_words=['I', 'am'],\n",
        "    predict_top_k=5,\n",
        "    checkpoint_path='checkpoint',\n",
        ")\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWA_zZielNAI"
      },
      "source": [
        "def get_data_from_file(train_file, batch_size, seq_size):\n",
        "    with open(train_file, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    text = text.split()\n",
        "\n",
        "    word_counts = Counter(text)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
        "    n_vocab = len(int_to_vocab)\n",
        "\n",
        "    print('Vocabulary size', n_vocab)\n",
        "\n",
        "    int_text = [vocab_to_int[w] for w in text]\n",
        "    num_batches = int(len(int_text) / (seq_size * batch_size))\n",
        "    in_text = int_text[:num_batches * batch_size * seq_size]\n",
        "    out_text = np.zeros_like(in_text)\n",
        "    out_text[:-1] = in_text[1:]\n",
        "    out_text[-1] = in_text[0]\n",
        "    in_text = np.reshape(in_text, (batch_size, -1))\n",
        "    out_text = np.reshape(out_text, (batch_size, -1))\n",
        "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBfwMP7zlPzZ"
      },
      "source": [
        "def get_batches(in_text, out_text, batch_size, seq_size):\n",
        "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
        "    for i in range(0, num_batches * seq_size, seq_size):\n",
        "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVMNrMHSlUca"
      },
      "source": [
        "class RNNModule(nn.Module):\n",
        "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
        "        super(RNNModule, self).__init__()\n",
        "        self.seq_size = seq_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size,\n",
        "                            lstm_size,\n",
        "                            batch_first=True)\n",
        "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.dense(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def zero_state(self, batch_size):\n",
        "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
        "                torch.zeros(1, batch_size, self.lstm_size))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRns5VXqlXeE"
      },
      "source": [
        "def get_loss_and_train_op(net, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "    return criterion, optimizer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FukDk_0LlcBl"
      },
      "source": [
        "def predict(device, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
        "    net.eval()\n",
        "    words = ['I', 'am']\n",
        "\n",
        "    state_h, state_c = net.zero_state(1)\n",
        "    state_h = state_h.to(device)\n",
        "    state_c = state_c.to(device)\n",
        "    for w in words:\n",
        "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "\n",
        "    _, top_ix = torch.topk(output[0], k=top_k)\n",
        "    choices = top_ix.tolist()\n",
        "    choice = np.random.choice(choices[0])\n",
        "\n",
        "    words.append(int_to_vocab[choice])\n",
        "\n",
        "    for _ in range(100):\n",
        "        ix = torch.tensor([[choice]]).to(device)\n",
        "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
        "\n",
        "        _, top_ix = torch.topk(output[0], k=top_k)\n",
        "        choices = top_ix.tolist()\n",
        "        choice = np.random.choice(choices[0])\n",
        "        words.append(int_to_vocab[choice])\n",
        "\n",
        "    print(' '.join(words).encode('utf-8'))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5EPmr9UlCHu",
        "outputId": "183e41bc-600c-4bef-d363-f10e625e2c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = get_data_from_file(\n",
        "        flags.train_file, flags.batch_size, flags.seq_size)\n",
        "\n",
        "    net = RNNModule(n_vocab, flags.seq_size,\n",
        "                    flags.embedding_size, flags.lstm_size)\n",
        "    net = net.to(device)\n",
        "\n",
        "    criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
        "\n",
        "    iteration = 0\n",
        "\n",
        "    for e in range(100):\n",
        "        batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
        "        state_h, state_c = net.zero_state(flags.batch_size)\n",
        "        state_h = state_h.to(device)\n",
        "        state_c = state_c.to(device)\n",
        "        for x, y in batches:\n",
        "            iteration += 1\n",
        "            net.train()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = torch.tensor(x).to(device)\n",
        "            y = torch.tensor(y).to(device)\n",
        "\n",
        "            logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
        "            loss = criterion(logits.transpose(1, 2), y)\n",
        "\n",
        "            loss_value = loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            _ = torch.nn.utils.clip_grad_norm_(\n",
        "                net.parameters(), flags.gradients_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if iteration % 500 == 0:\n",
        "                print('Epoch: {}/{}'.format(e, 100),\n",
        "                      'Iteration: {}'.format(iteration),\n",
        "                      'Loss: {}'.format(loss_value))\n",
        "\n",
        "            if iteration % 1000 == 0:\n",
        "                predict(device, net, flags.initial_words, n_vocab,\n",
        "                        vocab_to_int, int_to_vocab, top_k=5)\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size 11233\n",
            "Epoch: 1/100 Iteration: 500 Loss: 4.667932510375977\n",
            "Epoch: 2/100 Iteration: 1000 Loss: 4.295897960662842\n",
            "b'I am very good of this instant ! Stop thief . You know , \" rejoined Mr ; and he has a very thing to a few seconds and , as the same time of a great and good man . He is not very much ; for he has taken the door . He is , for some new suit . He was no great hand to his face , he said Mr ; he was no sooner a good friend ; for he was , and he would be a great hand on , with a few moments of the same'\n",
            "Epoch: 3/100 Iteration: 1500 Loss: 4.212600231170654\n",
            "Epoch: 5/100 Iteration: 2000 Loss: 3.8056488037109375\n",
            "b'I am good man , and a great deal more than of the same spot ! Two days were not been a little soothed as the same amiable was had been removed , for it would have done to be a few words as a very dark , and his hand to him . There was not . It may be sure to do . \" \" No . But it is so , for the girl , and that it would do the old lady and a great number that night was very . \" You will be done with the other'\n",
            "Epoch: 6/100 Iteration: 2500 Loss: 3.8088130950927734\n",
            "Epoch: 7/100 Iteration: 3000 Loss: 3.7238399982452393\n",
            "b'I am more careful you know it ! They had \" ve got into their hearts . I am sworn ? What ! \" cried Mr . Giles with the same . He had a few moments , the worthy gentleman in a chair , \" he has he was a man ; the girl pulled himself from his own thoughts , he would not have the same , in his hand . The two women itself to be hung ; \" I have no fault that it was the man ? If he has not . \" \\'that\\'s not for waddin ,'\n",
            "Epoch: 9/100 Iteration: 3500 Loss: 3.4113988876342773\n",
            "Epoch: 10/100 Iteration: 4000 Loss: 3.284987449645996\n",
            "b'I am here ? He says I know what he would say ! Coals . I \" d be , if we had enough of him , and the alternative \" I have seen you like it ? \" inquired Monks . Fagin nodded his head to be a man by this pleasantry for the Jew ; \" but I see it ? What ? Ha ! I see them . But , Fagin was in the way of the house , \" said Fagin : \" for this moment ! Fagin was quite very neatly at length , a good training ,'\n",
            "Epoch: 11/100 Iteration: 4500 Loss: 3.243401050567627\n",
            "Epoch: 13/100 Iteration: 5000 Loss: 3.261340618133545\n",
            "b\"I am here . It seems much injured . It is not for the same man ; I have no fictitious . He is very happy for some other spot ; for the other nurse ; it fell upon his hands on his face , the Jew had been able for him , when he was at once again : and so hungry , and he had no very different violent man . 'then watched you . The two gentlemen watched the old lady ; the old man who was in their hearts and crevices to that she was not to know that\"\n",
            "Epoch: 14/100 Iteration: 5500 Loss: 3.229599714279175\n",
            "Epoch: 15/100 Iteration: 6000 Loss: 3.2594823837280273\n",
            "b'I am of the house ; \" \" You would not refuse her . I will give his friend to morrow only holds his body ! \" exclaimed Noah ; and then the gentleman of his companion . \" A good lady ! Oh O ! Oh ! Better not , my friend , sir ? \" inquired Mrs . Bumble ; his and hoping he were no unfit head , with a moderately many years to be done , that she could be a good profit upon him , that he had no injurious for the first flight that which was sitting'\n",
            "Epoch: 16/100 Iteration: 6500 Loss: 3.108508825302124\n",
            "Epoch: 18/100 Iteration: 7000 Loss: 2.914419174194336\n",
            "b'I am very effective , or it\\'ll choke him to say . It is unfair . She seems for your own lips , my boy ? \" said Mrs , who died the other side , to the ground and his corner with terror ; which was a washerwoman ; the other boys gave the fathers they would had the same . \\'come ! Oh that I have lived with you in my mother\\'s sister ; for you are here knows anything about it , \" said Sikes . Mr , with an expression old collar away with great number of , and'\n",
            "Epoch: 19/100 Iteration: 7500 Loss: 3.0112664699554443\n",
            "Epoch: 20/100 Iteration: 8000 Loss: 3.092376232147217\n",
            "b'I am here . The two women , and , who was in this way . Weary , Mr ; he fell . It may have a great hole to him as if I can touch ? He has made rare cricket that he might have been the Artful at last . The old den the way . He was in front room . \" Yes ; I am leading to it ! I \" ve the boy ? He has come for a fool of your wrath , \" answered Rose , who , \" to stop , \" answered the old'\n",
            "Epoch: 22/100 Iteration: 8500 Loss: 3.080843448638916\n",
            "Epoch: 23/100 Iteration: 9000 Loss: 2.8710877895355225\n",
            "b'I am following me dress . I was the worst of thing for it . He looked upon her ; for it were a beadle : pointed upward in the inn room . He was very naturally ; but the stranger , in his pockets , had buoyed them into byways to quell paupers , who was prevented to their work , but that if they could , having recently interfered in her head . They halted and for his hands , or sweepstakes , he said ; which in jest , the two hastened to the unhappy creature as the man ,'\n",
            "Epoch: 24/100 Iteration: 9500 Loss: 3.1355702877044678\n",
            "Epoch: 26/100 Iteration: 10000 Loss: 3.0966997146606445\n",
            "b'I am very pale . \" \\'there\\'ll , \" rejoined the old woman who had never been brought by his head , for the old man ; the beadle and his pipe had not , at length , as if they descended the apartment into an easy friend . As Mr to the workhouse , the Dodger and Mr . Losberne ; and Mr ; but it was not for a jailer ; the rain no fear his head , for the old housekeeper and bade Fagin ; for it hadn\\'t been disturbed in his hand . The old lady was the wildest'\n",
            "Epoch: 27/100 Iteration: 10500 Loss: 3.180310010910034\n",
            "Epoch: 28/100 Iteration: 11000 Loss: 2.8784055709838867\n",
            "b'I am too bold faced instant of the very service ; which he would not the time , \" cried Mrs ; yelling ; reserving Rose herself before the fire , with an expression that was droll and window : and took off at his knees . \" It hurts me to me , you have come from him if I can be consigned by the arm , you deserve my friend ? \" \" Yes ! Young ! Oh , not you to give us . But the news should to the done that the board and lodging . He was to'\n",
            "Epoch: 29/100 Iteration: 11500 Loss: 3.1171412467956543\n",
            "Epoch: 31/100 Iteration: 12000 Loss: 3.2399628162384033\n",
            "b'I am too , from the streets . He is a very dark corner ; and flying would never succeed . He knows no resource ; and that if it was very heartily ; and the Dodger had scoured the windows of the house had had grown stout , \" he asked , \" I don\\'t care for yourselves ! \" Talking as well and every triumph as milk . \" \" No more ? \" asked Noah . The Jew nodded , \\'to whom it is , and a great deal iron , if yer was a sortin \" inquired the doctor'\n",
            "Epoch: 32/100 Iteration: 12500 Loss: 2.8991830348968506\n",
            "Epoch: 33/100 Iteration: 13000 Loss: 2.9140424728393555\n",
            "b'I am well , if I am to deal with me as he is not , in your own head ! Stay . Mealy meat from a man ? They\\'ll the place for it would go , that it may live , and we not know that he would have to tell him money , as if he agreed a little of it Bolter\\'s , but a lie upon the side to a show , \" replied Fagin thoughtfully \" Harry \" un , no man who had not , that the jailer brought them up to a reply where his consequent ,'\n",
            "Epoch: 35/100 Iteration: 13500 Loss: 2.8462979793548584\n",
            "Epoch: 36/100 Iteration: 14000 Loss: 2.7467665672302246\n",
            "b'I am ma and had no and deadly feeling had been the clergyman in his eyes ; but as if he was roused himself from a loud kicking out . The Jew looked up at a chair with all matters who could . As the old lady emerged . \\'so pleasure \" observed the relict of his own child in a towering passion ; \" and was the smallest danger to take him into company with me that I can tell you to be the pupil of eating . Come here , my own ! \" \" Not what I do to see'\n",
            "Epoch: 37/100 Iteration: 14500 Loss: 3.152552366256714\n",
            "Epoch: 39/100 Iteration: 15000 Loss: 2.689908981323242\n",
            "b\"I am here ; don't think it is . In this time , and the tinker ; but friendship to that the dog was infernal unconstitutional that nature , and a very great deal better for some minutes . On the slightest part : as he was completely exhausted , as he spoke . He had not met the struggles . He was still placidly walking away and preparation . There , the whole city also actually , in a long silence , and with him about it . The old men came into the old lady and throwing off his goods ,\"\n",
            "Epoch: 40/100 Iteration: 15500 Loss: 2.80165433883667\n",
            "Epoch: 41/100 Iteration: 16000 Loss: 2.907480239868164\n",
            "b'I am here , my friend ? And what\\'s the same thing you are charged with a file now ; \" but I don\\'t think I am very glad , \" replied Rose Maylie . \" What I should have known the night afore this maudlin thing for some of safety had taken . This was all the building . I don\\'t know that this system was afraid . I know , Mrs ! Young Twist ; \" he will never reach the night before I should say you have been the better . Being dragged himself off , that it is ,'\n",
            "Epoch: 42/100 Iteration: 16500 Loss: 2.870919704437256\n",
            "Epoch: 44/100 Iteration: 17000 Loss: 3.0454204082489014\n",
            "b'I am neat . Eh ? He would have done , if I was going on \" \" Bolter the dirtiest Mr with sundry noble trees as easily a set of palace . It is , to night ; it warn\\'t for a minute of their search , are you ? It would never be picked up here and My horse the door yielded to a small pieces about the smoke and Having stopped with extraordinary in his own person in the same anxious , that he might acquire in the same subject and safety . He\\'s you permit ; then ? Tell'\n",
            "Epoch: 45/100 Iteration: 17500 Loss: 2.7787399291992188\n",
            "Epoch: 46/100 Iteration: 18000 Loss: 2.788100004196167\n",
            "b\"I am usually interesting angry part : five and singular child may a dear old man against him away simultaneous that I was to see that . The knocking was sitting of that gentleman's house in a low and low and stupefied from it . His ear ! They purposed remaining occasion to see that Mr . Sikes , commenced the wrist hand was Brownlow looking with the white waistcoat ; strains the stairs paused up , until he came in his hands . His back were confirmed ten by the appearance . At him to a yellow town proof , that gentleman's\"\n",
            "Epoch: 48/100 Iteration: 18500 Loss: 3.035867929458618\n",
            "Epoch: 49/100 Iteration: 19000 Loss: 2.808248519897461\n",
            "b'I am neat and hurry against it . He knows how you do you ? You won\\'t have done ? Speak very well as he fell on , \" rejoined Nancy ; and as the girl to provoke ; \\'suppress , if she died ; but the latter recognition , might have awakened his mind ; and , the old man who , having a very great many girl to his yellow friends . \" You have you like to do you that , and you do me all , and preached , I am very glad . I know that ; and'\n",
            "Epoch: 50/100 Iteration: 19500 Loss: 2.9454400539398193\n",
            "Epoch: 52/100 Iteration: 20000 Loss: 2.773944854736328\n",
            "b\"I am very stiff . It was not ill again : so to produce them in the ferry quarter . At a hearty parish losses the distance ; the girl himself threw herself , in irrepressible astonishment at a distance , and temples ; the windows was a candle , by longer against him . It once again then , to the gentleman with his friend's , that he fired his throat without any further remark . This suggested angry , and a young lady of no use to the bill . Here they did not mean by justice without saying the lower\"\n",
            "Epoch: 53/100 Iteration: 20500 Loss: 2.8873722553253174\n",
            "Epoch: 54/100 Iteration: 21000 Loss: 2.792698860168457\n",
            "b'I am very hard to the backs and losses and timber upon your cap in your ears when Conkey illness and seal that I , there was , in a block thickest a week before ! In this position , affectionately ! Don\\'t you know that this were uppermost in the Stone Jug ; and that in our beds , or the old women ! I have not to be done ? He inquired if we have known you . Mind , Mr . Losberne , laying her hand into her hands , \" it\\'s a stout personage on the rumour . \\'mr'\n",
            "Epoch: 55/100 Iteration: 21500 Loss: 3.001024007797241\n",
            "Epoch: 57/100 Iteration: 22000 Loss: 2.857158899307251\n",
            "b\"I am usually shrewd cry on Saffron that young child , which they can resolve in a row ? It would never succeed , and he sends disgrace away with his grasp . He is , Mr to describe ; the boy's sight alive : for it might forget it a humourous candle ; he was evidently and shadowy from us ; so , the Dodger was the big coat , and smiled in a low earthy doctor with a select situation of his eyes : and the old gentleman had returned to him : as she dropped a bundle in alarm as\"\n",
            "Epoch: 58/100 Iteration: 22500 Loss: 2.5383894443511963\n",
            "Epoch: 59/100 Iteration: 23000 Loss: 2.919498920440674\n",
            "b'I am going over me ? \" The old woman was not ill in a man in the affirmative . \\'there ! He\\'s sure we hadn\\'t of it . \" \\'shall he had taken , \" cried Fagin , turning quickly as before a satisfactory indignation ; a guilty hill he had seen him ; and when Mr . Sowerberry , regarding Oliver . The two attendants , indignantly by Mr ; \" I will see that lad , my boy . I know you , Lazy yourself ; you win where I have been able in visiting , which penetrated at the'\n",
            "Epoch: 61/100 Iteration: 23500 Loss: 2.5300350189208984\n",
            "Epoch: 62/100 Iteration: 24000 Loss: 3.0093765258789062\n",
            "b'I am of him ? I cannot follow , the night . He paused , at length , the girl had left her ; for a new train of corresponding two pocket ; the whole words fell upon his delivery ; \" and you are going here before ! I have borne . \" The Jew was heard at once : \" \" Nolly ? Do hear that I should not , ma and take it back , my dears ? \" The Jew shook , with a flood of toil , he could never desert them . He makes that the extent'\n",
            "Epoch: 63/100 Iteration: 24500 Loss: 2.720310926437378\n",
            "Epoch: 65/100 Iteration: 25000 Loss: 2.7645668983459473\n",
            "b'I am following \\'stop night , child , \" rejoined Sikes : \" I don\\'t mean come into the ditch in a hundred voices after out to a pride , that he could hardly stand to them . This suggested days . The conversation was busily occupied in its former : of his way , with an iron ; whistling with new gin , which terminated in a corner of which the fellow of thence hands before a long way in its inmates ; the robber the windows that had occurred , the shutters , as the limits and amusing his new friend'\n",
            "Epoch: 66/100 Iteration: 25500 Loss: 2.637094259262085\n",
            "Epoch: 67/100 Iteration: 26000 Loss: 2.784506320953369\n",
            "b'I am longer hole to me ; I can do that , in that clear and wickedness . Noah ? Oh said nothing ; but he has not been any of her . What is you stand vice ? Not ! \" exclaimed Mr : wisely alarmed , and looking round . Oliver was out , Noah attempted , in her pocket case ; and dreading a young gentleman turned his spectacles , as a good one , he had a lurking round . \\'to morrow , sir ? \" demanded Oliver : catching at once again , and he had no longer'\n",
            "Epoch: 69/100 Iteration: 26500 Loss: 2.914717674255371\n",
            "Epoch: 70/100 Iteration: 27000 Loss: 2.724029064178467\n",
            "b'I am good ones ! Lord . He had not , and so are the fellows that the Secretary of fraud : and a fierce and smelling bodies his own , and I tell me , if it is not to do , sir ; \" by a good gold speaker . Eh , \" rejoined Mrs , that the birthplace of the dog\\'s Whether of whom the Jew glanced contemptuously about his head gravely , at a perfect pupils . Fagin had a great brother of that way ; and , as if it was in no infant ; which he was'\n",
            "Epoch: 71/100 Iteration: 27500 Loss: 2.8810348510742188\n",
            "Epoch: 72/100 Iteration: 28000 Loss: 2.6916894912719727\n",
            "b'I am here boy Bridge ! They\\'ll swear . It chanced or so well known he is , that the boy was not yet . It is not here to know , my love ; I shouldn\\'t say him in the course . That was a little starved and swallowed one and history . Monks has been a regular body on one day ; but I don\\'t take the angels out . All if they had done , \" replied Sikes impatiently ; and a large key in a flood book ; the sinking back in the street , he drew her back'\n",
            "Epoch: 74/100 Iteration: 28500 Loss: 2.691195487976074\n",
            "Epoch: 75/100 Iteration: 29000 Loss: 2.790858745574951\n",
            "b'I am here here ; for I am to night , \" rejoined Rose ; \\'so we have not afraid from my life ? Not , I am , ma Mr , in saying with blood , as if to shiver and hate to recovery in astonishment ; for many tears might not to the table . The Jew , bowing a re out of a long silence . Once he is of this , I am , and I have been very much as before . However of sugar once reduced . This was the other long as it had referred to'\n",
            "Epoch: 76/100 Iteration: 29500 Loss: 2.7521917819976807\n",
            "Epoch: 78/100 Iteration: 30000 Loss: 2.6573550701141357\n",
            "b'I am too glad we have the boy . The girl , too often , by some surprise in a small , or he purchased the hue and darkness , and sustained a little impatience of three days \" Nancy\\'s looks was not to lock up ; than he had known how they had a little time for the dim people , for some time as he was in close and confusion . delight at his ease turned a loud shout ; the most stuck in which they reached home ; the girl felt a mist himself , and hint it would to'\n",
            "Epoch: 79/100 Iteration: 30500 Loss: 2.759795904159546\n",
            "Epoch: 80/100 Iteration: 31000 Loss: 2.5760464668273926\n",
            "b'I am sooner he ! He tried of hearts , he pushed the pain and delay was smiles and very little back to his own state of her own bosom ; while Charley , with an air in one hand on the table ; \" but one book to catch the beaks . To my own and so . If she has gone . \\'this green Never say ? \" demanded the gentleman with a groan of bread with her face aside his head with difficulty to the light : of his old nurse and station in behalf to make the greater impression'\n",
            "Epoch: 82/100 Iteration: 31500 Loss: 2.711477518081665\n",
            "Epoch: 83/100 Iteration: 32000 Loss: 2.608980178833008\n",
            "b'I am induced him needn\\'t observe , \" I know , you shall know what\\'s the ungrateful object but apt . What object it\\'s been very glad , or why do the crib . Ha ! you\\'re throat ! Good promise , \" retorted Sikes , with a sentimental of stairs ; \" I am ready . A very low or locket with you a woman who lodges for \" Oliver , with a threatening look , and pointing out , for her tardiness very obstinate had prayed her for a short , that she should have become and stuck on the table'\n",
            "Epoch: 84/100 Iteration: 32500 Loss: 2.7710800170898438\n",
            "Epoch: 85/100 Iteration: 33000 Loss: 2.5526797771453857\n",
            "b'I am certain that I have done you ! what do YOU live of . What way ! Jump of my deserting \" \" \" What do _you_ be . If they are ! God ! Jump , my friend . I am , \" answered Oliver . The girl rolling ceased to awaken some long time he would never have the responsibility pains of vicious clothes and darkness . She had been poring by that time to be heard yourself from a couple from their journey , and that he was enabled in fields ; but the Dodger wore a short smock'\n",
            "Epoch: 87/100 Iteration: 33500 Loss: 2.526064157485962\n",
            "Epoch: 88/100 Iteration: 34000 Loss: 2.7983412742614746\n",
            "b'I am following me Bolter\\'s throat as you can . The Dodger looked up at the office : the beadle , \" if he had ever not easily start before the bluff man stammered Rose , to whom the gentleman , with great effort than treachery and buffeted up from a few steps : which , the old lady and his partner received in , the example the moment , by a nicety one hour whose unhappy \\'certainly . I see , my man , I repeat , wrench , although I have lived a boy , \" said Fagin ; \\'there\\'s a'\n",
            "Epoch: 89/100 Iteration: 34500 Loss: 2.7495431900024414\n",
            "Epoch: 91/100 Iteration: 35000 Loss: 2.6473958492279053\n",
            "b'I am dreary passage touch ! Scarce . Some dirty room which you take the right fellows to your young child ! And the young woman ! Come ! Let trial , my friend , the doctor awakened with your old days in a good train and worthy glass of a mile and hedge down to her hand , \" he had better say a little longer space ; caught up the grave . \\'tell me evil grandfather or four before , that it had taken a strange sort that night : giving only punishable or the violent children ; but a little'\n",
            "Epoch: 92/100 Iteration: 35500 Loss: 2.86836314201355\n",
            "Epoch: 93/100 Iteration: 36000 Loss: 2.567044496536255\n",
            "b'I am certain of you that I had been sealed on one ma nor master\\'s and game . \\'they\\'re one o he ? And please ; promising he said , with the old gentleman and death as he had reassured passed : which , to a scream , for his wife ; \" and hoping you will ? He cried , sir ? What ! Better to see him ? Why not ? \" inquired Fagin ! \" \" Yes ! You can\\'t get rid to you ? Mr to the ground with some new comers , with the rapidity and desolation ,'\n",
            "Epoch: 95/100 Iteration: 36500 Loss: 2.6414554119110107\n",
            "Epoch: 96/100 Iteration: 37000 Loss: 2.8564229011535645\n",
            "b'I am dreary gin and hour , as you a woman ? Oh ? \" The attendant rose up with the same colour ; which was secured he might acquire that equanimity Nancy should overtake that the Jew and her ear , he had scarcely washed by London on the room ; \" I \" wished it was a regular right ! Why do it ? What right ? Oh that I was very sorry for a wery numerous for many weeks . He was still with great excited comfortable . It grew silent and feeble body of a laugh , as she'\n",
            "Epoch: 97/100 Iteration: 37500 Loss: 2.7435383796691895\n",
            "Epoch: 98/100 Iteration: 38000 Loss: 2.9160237312316895\n",
            "b'I am going over the room where she was very kind or two ladies , on account of me so much it . That would have seen the advertisement ! and the crib with him on his way in a retrospective pocket , and the clerk , recounted he remembered he clearly thought , to the house . She could have to speak a ladder ; over the body in his impatience to him . He was conveyed out by a tremendous hours . The old gentleman was plain from a steep staircase the time , he managed to the cause . \"'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LIoL6U33Myd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}